.. _release.0.5.0-notes:

=========================
smash 0.5.0 Release Notes
=========================

The smash 0.5.0 release continues the ongoing work to improve the handling, fix possible bugs, clarify the documentation. The highlights are:

- Reading atmospheric data with YYYY/MM/DD access
- New regularization function
- Spatial disaggregation/aggregation of the input raster
- Fix bugs in mesh creation, signature calculation and regularization l-curve

------------
Contributors
------------

This release was made possible thanks to the contributions of:

- Maxime Jay-Allemand
- Ngo Nghi Truyen Huynh
- Fran√ßois Colleoni

------------
Deprecations
------------

BayesResult object
******************

The ``density`` attribute of the :class:`smash.BayesResult` object has been deprecated in preparation for the upcoming release 1.0.0. 
The other two attributes, ``data`` and ``lcurve``, are still available and can be used for further analysis. 

------------
Improvements
------------

Reading atmospheric data with YYYY/MM/DD access
***********************************************

This mode is triggered by enabling the flag prcp_yyyymmdd_access in the model setup file. The atmospheric data files are supposed to be stored in a directory YYYY/MM/dd. This option is useful if the model is ran time step by time step (many incremental runs). In that case searching the atmospheric data files can be relatively slow (1 second multiplicate by the number of runs). With this mode it is optimized and it is faster. 

------------
New Features
------------

New regularization function
***************************

hard-smoothing : the smoothing regularization function is applied on parameters or states directly. This behavior differs from the ``smoothing`` mode where the regularization is applied on the difference between the background and the control (parameters or states)

New functions for reading and writting hdf5 files
*************************************************
 
The new functions are generic. You can save a dictionary to an hdf5, save an object (not only smash) to an hdf5, read an object as dictionary, read an hdf5 as a dict, read an hdf5 as a smash model object. Functions are provided by smash.io.hdf5_io.py. hdf5 can be opened in read-only to provide several simultaneous access. During the export or the reading, the structure of the dictionary or object is preserved. When saving an object or a dictionary in an hdf5, the location can be specified so that dictionary or object can be saved side by side at different places.

Spatial disaggregation/aggregation of the input raster
******************************************************

If the resolution of the input raster is different from the resolution of the model mesh, the input rasters are automatically reprojected by gdal. In that case the reading of the input can be slower. For best performances, it can be useful to preprocess the input files (precipitations).

-----
Fixes
-----

Boundary conditions checking
****************************

The boundary condition checking previously used a tolerance of 1e-6, which caused issues in certain cases due to machine precision when passing from Python to Fortran via the f90wrapper.
To address this problem, the tolerance has been decreased to 1e-3.

See issue `#23 <https://github.com/DassHydro/smash/issues/23>`__.

Bug fixes when generating the l-curve.
**************************************

Issues have been solved when selecting the optimal weight for the regularization term.

Event signatures computation
****************************

The bug related to the computation of flood event signatures has been resolved for specific cases where the peak event is observed during the last time steps in the time window.

See issue `#28 <https://github.com/DassHydro/smash/issues/28>`__.

Segmentation algorithm
**********************

If multiple events are detected, the duration of the merged event is no longer constrained by the max duration parameter. Instead, its duration may exceed this value.

Catchment delineation segmentation fault
****************************************

An error occured when two neighboring cells have antagonistic flow directions ``(1, 5)``, ``(2, 6)``, ``(3, 7)``, ``(4, 8)``. This should be corrected directly in the flow direction file but to avoid 
segmentation faults when the maximum number of recursions has been reached, a check is added to the code to exit recursion in that case.

See issue `#31 <https://github.com/DassHydro/smash/issues/31>`__.

Catchment flow distances on adjacent non-nested catchments
**********************************************************

There is a bug when calculating flow distances when two adjacent catchments are considered in the mesh but non-nested. During calculation, a flag is set around the 8 adjacent cells of each upstream cell and not on the upstream cell in particular. As a result, a gauge stuck to a cell of another catchment will not be considered as a non-nested gauge and will be filled with -99. The bug has been solved by flagging only the upstream cell and not the 8 adjacent cells.

See issue `#38 <https://github.com/DassHydro/smash/issues/38>`__.

Correctly handle Nodata value during the spatial disaggregation of the rainfall
*******************************************************************************

A crash occured during the disaggregation of the rainfall. The creation of a GDAL virtual-destination failed when the parent geotiff file has its Nodata value unset (None type). When this is the case, the Nodata value of the disaggregation rainfall is automatically set to -99.

See issue `#40 <https://github.com/DassHydro/smash/issues/40>`__.

Stop the execution of smash when ``start_time`` is equal to ``end_time``
************************************************************************

When ``start_time`` is equal to ``end_time``, the code crashes during the data reading with no obvious reason. Now just stop the code execution and return an error when this case occurs.

See issue `#41 <https://github.com/DassHydro/smash/issues/41>`__.
